---
layout: default
title: Additional Work
nav_order: 5
---

# Know about my additional works
{: .fs-8, .no_toc}
<details open markdown="block">
  <summary>
    Table of contents
  </summary>
  {: .text-delta }
- TOC
{:toc}
</details>

---
## Self Driving Online Course
{: .fs-6}
<br>
The 6 month Udacity course helps to establish a knowledge on self driving cars.
<br>
<br>
### 1. Lane Detection [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shruthipv96/CarND_Udacity_Lane_Detection)
<br>
The goal is to find the lanes on the road using camera and py-OpenCV library.

In the below video, the red lines(output) are marked  over the lane markings.

<center>
 <iframe width="920" 
         height="500" 
         src="https://github.com/shruthipv96/portfolio3/assets/32814013/618dbfe6-359f-48f7-9cb9-362941587e93" 
         title="Output" 
         frameborder="0" 
         allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
         allowfullscreen>
 </iframe>
</center>

### 2. Advanced Lane Detection [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shruthipv96/CarND_Udacity_AdvancedFindingLane)
<br>
The goal is to find the lanes on the road in a more realistic environment like shadows, curves, etc.

In the below video, you can find the green area (output) indicating the lane. Additionally, the radius of curvature of the road and the offset of the vehicle from the center of the lane is also displayed.

<center>
 <iframe width="920" 
         height="500" 
         src="https://github.com/shruthipv96/portfolio3/assets/32814013/7e0f3c1f-620d-4296-b824-b3f78753ac7e" 
         title="Output" 
         frameborder="0" 
         allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
         allowfullscreen>
 </iframe>
</center>

### 3. Traffic Sign Classifier [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shruthipv96/CarND_Udacity_TrafficSignClassifier)
<br>
The goal is to classify various traffic signs on the road using Neural Network which helps to make a decision about how to proceed our driving
The open source German traffic sign dataset is used to train the network.

In the below image,the test image against the top predictions by the trained ML model is shown.
<center> <img src="https://github.com/shruthipv96/portfolio3/assets/32814013/ee1912b8-2948-4961-85b8-1638814d7967"> </center>

### 4. Behavioural Cloning [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shruthipv96/CarND_Udacity_BehaviouralCloning)
<br>
The goal is to clone the behaviour of our driving using deep neural network. The data was collected by driving the car by myself in the simulation.

In the below video, the car is driving by self without any user input based on the model trained. Input to model is camera feed and output from model is the steer angle. (Note: The video quality is poor because it is exported from simulation)

<center>
 <iframe width="320" 
         height="160" 
         src="https://github.com/shruthipv96/portfolio3/assets/32814013/e39c0081-c35b-46fe-86b6-4f672fd049bf" 
         title="Output" 
         frameborder="0" 
         allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
         allowfullscreen>
 </iframe>
</center>

### 5. Extended Kalman Filter [![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shruthipv96/CarND_Udacity_ExtendedKalmanFilter)
<br>
In reality, only the data from camera alone will not help to drive the car. We need to fuse Laser and Radar sensors to predict the position 
of the vehicle. The goal is to design a Kalman filter which can be used for both linear and non-linear models to predict the value based on input from multiple sources.

In the below image, the green triangle shows the predicted output. The blue and red circles indicate the input from Laser and Radar sensor.
<center> <img src="https://github.com/shruthipv96/portfolio3/assets/32814013/37652c1b-a11f-4a83-b7c8-ca65550ee6c3" width="640" height="480"> </center>

---
## Experimental Repositories
### Farming Solution

This project was developed for Hackathon to provide a smart farming solution. It includes live monitoring of soil nature (temperature, humidity from DHT-11 sensor using Raspberry Pi) and uploading into database, live billing of items in shops across the country using one central database and additional information regarding farming.
Website is run on xampp localhost server with php mySQL as backend database.

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shruthipv96/farmingsolution)

---
## College Projects

| Project      | Description     | 
|:-------------|:------------------|
| Digital Power Factor Meter |The meter developed finds the power factor of the load using microcontroller(Arduino) and its interrupt function. |
| Home Automation |  A system was developed where one can control home appliances using a smart phone. |
| Networking of motors | A prototype was developed where two independent motors were synchronized at same speed using Arduino. |
| Automated Cloth Protector | A system was developed to protect the clothes on terrace from rain using Arduino. |
| LabVIEW based Robotic Arm control | A model was developed in LabVIEW interfaced with Arduino to control a two degree of freedom robotic arm |

---
